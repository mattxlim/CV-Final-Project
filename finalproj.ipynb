{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f6e44d-2c60-4e87-b85a-1c874b5be11c",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)## COMP90086 Final Project\n",
    "\n",
    "Benjamin Tam (889835), Matthew Lim (895507)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2e15f9-bdcc-4def-b080-dde3cb74e506",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10192/3216871005.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# numpy compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m from pandas.compat import (\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mnp_version_under1p18\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_np_version_under1p18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m from pandas.compat.numpy import (\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mnp_array_datetime64_compat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# numpy versioning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\pandas\\util\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from pandas.util._decorators import (  # noqa\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[0;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\pandas\\_libs\\interval.pyx\u001b[0m in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2  \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers, optimizers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import pixellib\n",
    "from pixellib.instance import instance_segmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8a1623-3bb2-45c1-a654-300d99fb13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True Label\n",
    "def get_true_label(label_id):\n",
    "    return list(train_generator.class_indices.keys())[list(train_generator.class_indices.values()).index(label_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103f225d-75bc-4f43-aad6-2158fae0b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise image data generator\n",
    "# With validation split\n",
    "\n",
    "\n",
    "# Add rotation range\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                               validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf3caa0f-bf63-46ad-9f45-581620bf8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./\"\n",
    "train_path = './COMP90086_2021_Project_train/train'\n",
    "test_path = './COMP90086_2021_Project_test/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c61e4b5-9ffb-48d7-8036-ab80c2cf1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train labels from csv\n",
    "train_labels = pd.read_csv(os.path.join(\"./COMP90086_2021_Project_train\", \"train.csv\"), dtype=str)\n",
    "train_labels['id'] = train_labels['id'].apply(lambda x: '{}.jpg'.format(x))\n",
    "\n",
    "# Preprocess to get categorical class from coordinates. \"x,y\" used\n",
    "train_labels['xy'] = train_labels['x'] + \",\" + train_labels['y']\n",
    "train_labels['xy'] = train_labels['xy'].astype('category')\n",
    "\n",
    "train_labels['cat'] = train_labels['xy'].cat.codes\n",
    "\n",
    "\n",
    "# Import train labels from csv\n",
    "test_labels = pd.read_csv(os.path.join(\"./COMP90086_2021_Project_test\", \"imagenames.csv\"), dtype=str)\n",
    "test_labels['id'] = test_labels['id'].apply(lambda x: '{}.jpg'.format(x))\n",
    "\n",
    "\n",
    "# Integer encoding for coordinate label\n",
    "# train_labels['encoded'] = preprocessing.LabelEncoder().fit_transform(train_labels['xy'])\n",
    "# train_labels['encoded'] = train_labels['encoded'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9c7f321-7b70-43f1-9762-1c561748c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(train_labels.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad4e685-d405-4ceb-9710-fec2d5cbcc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 validated image filenames belonging to 1499 classes.\n",
      "Found 1500 validated image filenames belonging to 1499 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_labels, \n",
    "                                               directory = train_path,\n",
    "                                               x_col = 'id', y_col = 'xy',\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode=\"sparse\",\n",
    "                                                   subset='training')\n",
    "val_generator = train_datagen.flow_from_dataframe(train_labels, \n",
    "                                               directory = train_path,\n",
    "                                               x_col = 'id', y_col = 'xy',\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode=\"sparse\",\n",
    "                                                   subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae46155-37df-4398-a8f9-4aede64b67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_lbl = next(iter(train_generator))\n",
    "val_imgs, val_lbl = next(iter(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d70652-8cef-4590-97aa-842bb5dc725c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e94af08a-a6b7-4c5d-8e39-870994fe6984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'66.51932192,-44.01728035'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To obtain label ID\n",
    "np.argmax(train_lbl[2])\n",
    "\n",
    "# To obtain True label\n",
    "get_true_label(1373)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca8b7027-50f9-48cd-b817-192de4cb5d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4901961 , 0.5294118 , 0.5647059 ],\n",
       "        [0.4901961 , 0.5294118 , 0.5647059 ],\n",
       "        [0.4901961 , 0.5294118 , 0.5647059 ],\n",
       "        ...,\n",
       "        [0.41176474, 0.42352945, 0.39607847],\n",
       "        [0.41176474, 0.42352945, 0.39607847],\n",
       "        [0.4039216 , 0.4156863 , 0.38823533]],\n",
       "\n",
       "       [[0.4901961 , 0.5294118 , 0.5647059 ],\n",
       "        [0.4901961 , 0.5294118 , 0.5647059 ],\n",
       "        [0.4901961 , 0.5294118 , 0.5647059 ],\n",
       "        ...,\n",
       "        [0.41176474, 0.42352945, 0.39607847],\n",
       "        [0.41176474, 0.42352945, 0.39607847],\n",
       "        [0.4039216 , 0.4156863 , 0.38823533]],\n",
       "\n",
       "       [[0.4901961 , 0.5294118 , 0.5647059 ],\n",
       "        [0.4901961 , 0.5294118 , 0.5647059 ],\n",
       "        [0.49411768, 0.53333336, 0.5686275 ],\n",
       "        ...,\n",
       "        [0.41176474, 0.42352945, 0.39607847],\n",
       "        [0.40784317, 0.41960788, 0.3921569 ],\n",
       "        [0.40784317, 0.41960788, 0.3921569 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.31764707, 0.33333334, 0.3803922 ],\n",
       "        [0.3254902 , 0.33333334, 0.3803922 ],\n",
       "        [0.31764707, 0.31764707, 0.34901962],\n",
       "        ...,\n",
       "        [0.36078432, 0.37647063, 0.32156864],\n",
       "        [0.3529412 , 0.38431376, 0.33333334],\n",
       "        [0.40000004, 0.39607847, 0.31764707]],\n",
       "\n",
       "       [[0.28627452, 0.29803923, 0.33333334],\n",
       "        [0.29411766, 0.29411766, 0.3254902 ],\n",
       "        [0.23529413, 0.23137257, 0.25490198],\n",
       "        ...,\n",
       "        [0.3647059 , 0.3803922 , 0.3254902 ],\n",
       "        [0.34901962, 0.3803922 , 0.32941177],\n",
       "        [0.3803922 , 0.37647063, 0.29803923]],\n",
       "\n",
       "       [[0.25490198, 0.25882354, 0.2784314 ],\n",
       "        [0.21568629, 0.21176472, 0.23137257],\n",
       "        [0.21960786, 0.21176472, 0.22352943],\n",
       "        ...,\n",
       "        [0.36078432, 0.37647063, 0.32156864],\n",
       "        [0.37647063, 0.40784317, 0.35686275],\n",
       "        [0.36078432, 0.35686275, 0.2784314 ]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a877f5-4354-4679-addf-fce74358b368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f2dcf7-429b-427f-a143-e69d23af7636",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use VGG19 to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2f083694-b0aa-4b0e-9f4f-60db50594d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5825e99e-bf68-4939-a776-a8b717255e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = VGG19(weights='imagenet', input_shape=[150,150,3],include_top=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "90965a81-e7a7-4df2-972e-1b8e42242e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract = Model(base_model.inputs, base_model.get_layer('block5_conv4').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "84552a0e-6228-47f5-a9e9-ce7109125820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = extract.predict(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06145495-040c-45ed-9687-ac9f5b8e8a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "62e62cec-6e1c-4d6a-be7c-5436951427f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_classes, optimizer, fine_tune=0):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with VGG16 pretrained layers\n",
    "    \n",
    "    input_shape: tuple - the shape of input images (width, height, channels)\n",
    "    n_classes: int - number of classes for the output layer\n",
    "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
    "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
    "                If set to 0, all pretrained layers will freeze during training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = VGG16(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "    \n",
    "    # Defines how many layers to freeze during training.\n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    # depending on the size of the fine-tuning parameter.\n",
    "    if fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc650d04-7a20-4f08-b5ee-f92fd0412844",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (150, 150, 3)\n",
    "optim_1 = Adam(learning_rate=0.01)\n",
    "n_classes=1499\n",
    "\n",
    "n_steps = train_generator.samples // batch_size\n",
    "n_val_steps = val_generator.samples // batch_size\n",
    "n_epochs = 50\n",
    "\n",
    "# First we'll train the model without Fine-tuning\n",
    "vgg_model = create_model(input_shape, n_classes, optim_1, fine_tune=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc88a6-d749-4c8b-b0e2-78aee178ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f81971-5736-4258-a8fa-7205a18dd47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from livelossplot.inputs.keras import PlotLossesCallback\n",
    "from livelossplot import PlotLossesKeras\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "\n",
    "plot_loss_1 = PlotLossesCallback()\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='tl_model_v1.weights.best.hdf5',\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b856052-0ea4-4158-a3db-3f5fcbb12d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg_history = vgg_model.fit(train_generator,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=n_epochs,\n",
    "                            validation_data=val_generator,\n",
    "                            steps_per_epoch=n_steps,\n",
    "                            validation_steps=n_val_steps,\n",
    "                            callbacks=[tl_checkpoint_1, early_stop, plot_loss_1],\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60191fe-db63-48a5-b5bd-ed999a4d883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.reset()\n",
    "val_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a65509-e64c-4b1c-9650-69eb5fad86cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a40fc-5655-4637-920d-5eb60525baf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a1c04-cab2-436c-8d98-870518da5909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32bb1b3-824e-440d-9c0d-70ea12fc89f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2dd5d1-17f1-4b03-8c4b-ea603f4de978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "871ab15b-135e-4b96-8d27-4f31c33b4f49",
   "metadata": {},
   "source": [
    "## Instance Segmentation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d112af2-6baa-4049-bd5d-68f991fed7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mattlim\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "instance_seg = instance_segmentation()\n",
    "instance_seg.load_model(\"mask_rcnn_coco.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf7e2015-8d15-4d40-a365-183cfcbc2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_classes(train_path, image_filename, instance_seg, pbar=None):\n",
    "    segmask, output = instance_seg.segmentImage(os.path.join(train_path, image_filename))\n",
    "    if pbar:\n",
    "        pbar.update(1)\n",
    "    return segmask['class_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32654ed-ec13-4c94-9ce1-4f34570fb87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adbc46a1-f3c0-4913-b0f2-dfe84f0f4b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7971b057eee64904a6ad4beadc67b88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7208/1524861590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_object_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance_seg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8739\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8740\u001b[0m         )\n\u001b[1;32m-> 8741\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8743\u001b[0m     def applymap(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7208/1524861590.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_object_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance_seg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7208/1167221072.py\u001b[0m in \u001b[0;36mget_object_classes\u001b[1;34m(train_path, image_filename, instance_seg, pbar)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_object_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance_seg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msegmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance_seg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegmentImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msegmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\pixellib\\instance\\__init__.py\u001b[0m in \u001b[0;36msegmentImage\u001b[1;34m(self, image_path, show_bboxes, segment_target_classes, extract_segmented_objects, save_extracted_objects, mask_points_values, output_image_name, text_thickness, text_size, box_thickness, verbose)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Processing image...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\pixellib\\instance\\mask_rcnn.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, images, verbose)\u001b[0m\n\u001b[0;32m   2462\u001b[0m         \u001b[1;31m# Run object detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2463\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmrcnn_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2464\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmolded_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2465\u001b[0m         \u001b[1;31m# Process detections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2466\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    977\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CV Working\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4031\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 4032\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   4033\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4034\u001b[0m     output_structure = tf.nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1479\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=train_labels.shape[0])\n",
    "train_labels['objects'] = train_labels.apply(lambda x: get_object_classes(train_path, x['id'], instance_seg, pbar), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4369d2f5-06de-40c3-9a0d-a94ecd8e6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.to_csv(\"train_labels_objects.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84eb300-8505-47b6-a09d-49bee71ce85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.iloc[1235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85648e-ee06-45da-9387-aabe079b9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_labels[\"xy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f83166-b09d-4217-b34f-2d78b63c1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "d['hello'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea341c0-f5f0-4c3c-8323-c68b095f09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcdbac1-a573-428a-a78b-2139812f95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coord_objects = {}\n",
    "# for item in train_labels.values:\n",
    "#     try:\n",
    "#         coord_objects[item[3]] = np.concatenate((coord_objects[item[3]], item[4]))\n",
    "#     except KeyError:\n",
    "#         coord_objects[item[3]] = item[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88b1ec-88a1-4aa0-9b78-652bb423b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=coord_objects['-9.380678081,3.58271965']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2759db3-46ed-4f55-955f-a7d64fe69106",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[1, 1, 1, 1, 78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac932c75-905f-4eac-8ca6-eabfed2e19bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181c05d-0482-4319-8337-d73a1e7ac07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad47b4-58cd-4abf-aed3-5549f3e1cee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42cc6e1-561e-4d16-ad0c-7384d7796618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec994b0-8218-42a4-8761-34cd540b0a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b35816-5eee-4d84-9521-8fa58d1911ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c9c6e-7f3d-4c8f-8640-d8ffd7402622",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmask, output = instance_seg.segmentImage(os.path.join(train_path, \"IMG2744_2.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646c28a-8355-493a-b0be-f04ffad1533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmask['class_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e501ff-a3a0-4116-8a97-84f31804f55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb9b2a9-bab2-4541-8312-6f2da3281336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b21506-517a-40c4-be4c-3c7fc937246d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41ca8f-7ea2-4ac4-b00b-860ef91c09ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671223c-6de4-4cc0-b5e2-c5a3628da761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995e177-0830-4103-b4a6-a25bb9655f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29b3e7-30ed-459d-a48f-9a7c659f7329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c122ff7-dcb3-416a-af25-43893ade31f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5eabd-27e3-4e4e-99e1-4dc4bd297f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d0868c6-2896-4e10-8233-b743dec0a4a2",
   "metadata": {},
   "source": [
    "## Method 2: SIFT keypoints and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe5ea030-c70b-4c01-87a4-83c7f42d7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c33077af-4921-4f10-8ad5-7fc4af7cab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_compute(image):\n",
    "    \n",
    "    return sift.detectAndCompute(image, None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df67d2d0-dc5d-4544-a367-4f04b59dfb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_read_image(path, file_name, pbar=None):\n",
    "    image = cv2.imread(os.path.join(path, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "    if pbar:\n",
    "        pbar.update(1)\n",
    "    return (sift.detectAndCompute(image, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f1379d3-7193-419e-a8e7-89a119a52edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40ce8fb86e849199b435d4eca4c16dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7208/404671703.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# kp desc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sift_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msift_read_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7208/404671703.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# kp desc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sift_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msift_read_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7208/2668319361.py\u001b[0m in \u001b[0;36msift_read_image\u001b[1;34m(path, file_name, pbar)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find key points and descriptors for all items in training set\n",
    "# kp desc\n",
    "pbar = tqdm(total=7500)\n",
    "train_labels['sift_data']=[sift_read_image(train_path, file_name, pbar) for file_name in train_labels['id']]\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b05505-b158-4ef4-9cc7-d2bcc2e785c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['sift_data'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443d4e9-bb28-4ab2-80a3-a0adf4181789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split DF into train val set\n",
    "train_df, val_df = train_test_split(train_labels, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640fce7-b48f-46df-aa47-3a65d4c2c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flann_match_only(des_query, des_train, pbar=None):\n",
    "    try:\n",
    "        des1 = des_query\n",
    "        des2 = des_train\n",
    "\n",
    "        # FLANN parameters and initialize\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks=50)   # or pass empty dictionary\n",
    "        flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "        # Matching descriptor using KNN algorithm\n",
    "        matches = flann.knnMatch(des1,des2,k=2)   \n",
    "        return len(matches)\n",
    "    except:\n",
    "        return 0\n",
    "    finally:\n",
    "        if pbar:\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2329999f-847f-48d0-9cc4-70904c28e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use FLANN based matcher \n",
    "def flann_matches(des_query, des_train, pbar=None):  \n",
    "    try:\n",
    "        des1 = des_query\n",
    "        des2 = des_train\n",
    "\n",
    "        # FLANN parameters and initialize\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = {} #dict(checks=40)   # or pass empty dictionary\n",
    "        flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "        # Matching descriptor using KNN algorithm\n",
    "        matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "        # Get good amtches\n",
    "        # Store all good matches as per Lowe's Ratio test.\n",
    "        good=0\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                good+=1\n",
    "                \n",
    "        return good\n",
    "    except:\n",
    "        # If no features\n",
    "        return 0 \n",
    "    finally:   \n",
    "        if pbar:\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468a956-b5fa-4891-a6cd-8cf67bcfa7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_loc(path, query_image_filename, train_labels):\n",
    "    \n",
    "    \n",
    "    # Find matches between query image and all training images\n",
    "    kp_query, des_query = sift_read_image(path, query_image_filename)\n",
    "    \n",
    "    pbar = tqdm(total=len(train_labels.index))\n",
    "    matches=[((item[0], item[1]),flann_matches(des_query, item[2][1], pbar)) for item in train_labels[['x', 'y', 'sift_data']].to_numpy()]\n",
    "#     matches=[((item[0], item[1]),flann_match_only(des_query, item[2][1], pbar)) for item in train_labels[['x', 'y', 'sift_data']].to_numpy()]\n",
    "    pbar.close()\n",
    "    \n",
    "    \n",
    "    # Get match list and store it in a dict to add up all keypoints for each location\n",
    "    return sorted(matches, key=lambda x:x[1], reverse=True)[0]\n",
    "    \n",
    "#     from collections import defaultdict\n",
    "#     result_dict = defaultdict(int)\n",
    "\n",
    "#     for i in matches:\n",
    "#         result_dict[i[0]] += i[1] \n",
    "\n",
    "#     # Find x y coord with most matched keypoints as per flann matcher\n",
    "# #     out = max(result_dict, key=result_dict.get)\n",
    "    \n",
    "#     out = sorted(result_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e9a06-13f7-4e18-a9bc-37bd7b44aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_query, des_query = sift_read_image(test_path, \"IMG4399_1.jpg\")\n",
    "kp_query2, des_query2 = sift_read_image(test_path, \"IMG4287_3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba5d3a-725f-48f0-8aca-6b8a50e81135",
   "metadata": {},
   "outputs": [],
   "source": [
    "flann_match_only(des_query, des_query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2aa72-b9b5-41a7-9e43-8123b8863f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_predicted_loc(test_path, \"IMG4569_3.jpg\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b033256-6eb7-4576-950f-bbb04c493c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac33175-76e8-4f6e-a2b1-c131c2eda4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get match list and store it in a dict to add up all keypoints for each location\n",
    "# sorted(match_list, key=lambda x:x[1], reverse=True)\n",
    "# from collections import defaultdict\n",
    "# result_dict = defaultdict(int)\n",
    "\n",
    "# for i in match_list:\n",
    "#     result_dict[i[0]] += i[1] \n",
    "\n",
    "# # Find x y coord with most matched keypoints as per flann matcher\n",
    "# max(result_dict, key=result_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb6c06-c6b3-4abb-bc45-ff3cc3dd38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results=[]\n",
    "for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136ecf4-01db-40b3-9aba-827a451f8793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1cd235-f9fe-470f-9d00-d5f3ea4a86da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27010944-346a-451d-9931-146592856b56",
   "metadata": {},
   "source": [
    "## Benchmark Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803d202-23de-4f58-9314-d0a3a57c8085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import imageio\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ec4e5-c023-4f65-920d-da2b12ef98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_encoder):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_encoder, name='input_layer')\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(32, kernel_size=3, strides= 1, padding='same', name='conv_1')(inputs)\n",
    "    x = layers.BatchNormalization(name='bn_1')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_1')(x)\n",
    "   \n",
    "    # Block 2\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides= 2, padding='same', name='conv_2')(x)\n",
    "    x = layers.BatchNormalization(name='bn_2')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_2')(x)\n",
    "   \n",
    "    # Block 3\n",
    "    x = layers.Conv2D(64, 3, 2, padding='same', name='conv_3')(x)\n",
    "    x = layers.BatchNormalization(name='bn_3')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_3')(x)\n",
    "    \n",
    "    # Block 4\n",
    "    x = layers.Conv2D(64, 3, 1, padding='same', name='conv_4')(x)\n",
    "    x = layers.BatchNormalization(name='bn_4')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_4')(x)\n",
    "    \n",
    "    # Final Block\n",
    "    flatten = layers.Flatten()(x)\n",
    "    bottleneck = layers.Dense(2, name='dense_1')(flatten)\n",
    "    model = tf.keras.Model(inputs, bottleneck, name=\"Encoder\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac80cf-a202-43a0-b17b-f0c3ca624db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(input_decoder):\n",
    "    # Initial Block\n",
    "    inputs = keras.Input(shape=input_decoder, name='input_layer')\n",
    "    x = layers.Dense(3136, name='dense_1')(inputs)\n",
    "    x = tf.reshape(x, [-1, 7, 7, 64], name='Reshape_Layer')\n",
    "    \n",
    "    # Block 1\n",
    "    x = layers.Conv2DTranspose(64, 3, strides= 1, padding='same',name='conv_transpose_1')(x)\n",
    "    x = layers.BatchNormalization(name='bn_1')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_1')(x)\n",
    "    \n",
    "    # Block 2\n",
    "    x = layers.Conv2DTranspose(64, 3, strides= 2, padding='same', name='conv_transpose_2')(x)\n",
    "    x = layers.BatchNormalization(name='bn_2')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_2')(x)\n",
    "   \n",
    "    # Block 3\n",
    "    x = layers.Conv2DTranspose(32, 3, 2, padding='same', name='conv_transpose_3')(x)\n",
    "    x = layers.BatchNormalization(name='bn_3')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_3')(x)\n",
    "   \n",
    "    # Block 4\n",
    "    outputs = layers.Conv2DTranspose(1, 3, 1,padding='same', activation='sigmoid', name='conv_transpose_4')(x)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Decoder\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ec808-b086-4bc4-b0fc-16105c1dac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005)\n",
    "def ae_loss(y_true, y_pred):\n",
    "    loss = K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782163b-10f1-4c82-b2f0-8beaf10a82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "\n",
    "    with tf.GradientTape() as encoder, tf.GradientTape() as decoder:\n",
    "      \n",
    "        latent = enc(images, training=True)\n",
    "        generated_images = dec(latent, training=True)\n",
    "        loss = ae_loss(images, generated_images)\n",
    "        \n",
    "    gradients_of_enc = encoder.gradient(loss, enc.trainable_variables)\n",
    "    gradients_of_dec = decoder.gradient(loss, dec.trainable_variables)\n",
    "    \n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients_of_enc, enc.trainable_variables))\n",
    "    optimizer.apply_gradients(zip(gradients_of_dec, dec.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b16be9-43c8-4d84-91ee-9b0882d5b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    \n",
    "epoch = 20\n",
    "train(train_generator, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f2566-0a5e-4748-8c09-8af68fb99fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b40da-31eb-476a-9729-0751461154a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229289e2-b4e2-4d4d-be91-05fb1342589a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5dbb21-c6a1-426d-b0b4-a865f47e74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer((150, 150, 3)),\n",
    "        \n",
    "        layers.Conv2D(8, (5, 5), activation='relu'), # fill in\n",
    "        layers.MaxPooling2D((2, 2)), # fill in\n",
    "        layers.Conv2D(16, (5, 5), activation='relu'), #fill in\n",
    "        layers.MaxPooling2D((2, 2)), # fill in\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1499, activation='softmax')\n",
    "    ], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4244a0-d728-47ee-8eff-16bb3886a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "           loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), #use SparseCategoricalCrossentropy because labels are integers. If the labels are one-hot representation, please use CategoricalCrossentropy loss.\n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb51bc5-34ca-4d9a-90e0-786fb0d6fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "#         steps_per_epoch=10,\n",
    "        epochs=20,\n",
    "        validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "        batch_size=batch_size)\n",
    "#         validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59371e43-ee8a-4eef-92d2-c16d661bc994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bfaba5-4580-4e7e-956c-2312fd39015e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f99e5-5cb0-42f1-8835-18e307747804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6254e5-880b-482c-922a-ff0b62432281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db48c36-c22e-4ae3-9223-984573f07654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479f3ac-a735-4e32-ac9d-c452e26232b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0678c-064b-4375-8d4e-a5adad2b4a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
